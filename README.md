
# Asistente Contextual desde PDF

Este proyecto permite cargar un archivo PDF y hacerle preguntas directamente, como si fuera un chatbot entrenado con ese contenido. Todo funciona desde una √∫nica plantilla en Google Colab.

---

## ¬øQu√© permite?

- Cargar cualquier PDF con contenido t√©cnico o te√≥rico (ej: res√∫menes, apuntes).
- Hacerle preguntas en lenguaje natural.
- Responder con base en el contenido del PDF.
- Si no tiene la respuesta en el PDF, intenta no inventar (se puede ajustar).
- Funciona con modelos ligeros como TinyLlama.

---

##  Requisitos

- Cuenta en Google (para usar Google Colab).
- No requiere GPU paga (funciona con la gratuita de Colab).
- No requiere clave de API.
- PDF legible (no escaneado, texto plano).

---

##  Etapas del sistema

1. **Carga de PDF**  
   Se extrae el contenido del archivo, se segmenta y se filtran fragmentos √∫tiles (m√≠nimo 20 palabras por bloque).

2. **Vectorizaci√≥n**  
   Se generan representaciones num√©ricas de los fragmentos usando `all-MiniLM-L6-v2` (modelo de embeddings).

3. **Indexaci√≥n FAISS**  
   Se crea una base de datos de vectores para b√∫squeda r√°pida y eficiente.

4. **Interfaz Gradio**  
   Se despliega una app donde:
   - Carg√°s el PDF.
   - Escrib√≠s una pregunta.
   - Eleg√≠s cu√°ntos fragmentos relevantes buscar.
   - El modelo responde bas√°ndose en esos fragmentos.

---

##  ¬øC√≥mo usarlo?

1. **Abr√≠ el Colab.**
2. **Ejecut√° todas las celdas** desde el inicio (instalan las dependencias y modelos).
3. **Carg√° un PDF** desde la interfaz.
4. **Escrib√≠ una pregunta.**
5. **Obten√© una respuesta basada en tu PDF!**

---

##  Personalizaciones posibles

- Cambiar el modelo de lenguaje (`TinyLlama`) por otro m√°s grande si ten√©s recursos.
- Ajustar la cantidad de fragmentos que se usan como contexto (`top_k`).
- Agregar botones para guardar el √≠ndice, respuestas, o historial.
- Incorporar memoria conversacional si quer√©s extenderlo.

---

##  Observaciones t√©cnicas

- Los embeddings son precomputados solo una vez por PDF.
- El modelo solo responde en base a lo que se recupera (no est√° entrenado).
- Si no hay informaci√≥n en el PDF, puede dar una respuesta gen√©rica o indicar que no sabe.
- Todo se mantiene en RAM durante la sesi√≥n del Colab.

---

##  Limitaciones

- No memoriza interacciones anteriores (no tiene estado de conversaci√≥n).
- No detecta autom√°ticamente si invent√≥ una respuesta (eso depende del usuario).
- No funciona bien con PDFs escaneados o im√°genes.

##  Pruebas

Este proyecto incluye un archivo adicional de pruebas automatizadas para evaluar la calidad de las respuestas del chatbot.

### ¬øQu√© eval√∫an las pruebas?
- Precisi√≥n de las respuestas: Se compara la respuesta generada con una respuesta esperada.
- Capacidad de recuperaci√≥n: Verifica si el chatbot encuentra la informaci√≥n relevante en el PDF.
- Resistencia al alucinamiento: Eval√∫a si el modelo evita inventar contenido cuando la respuesta no est√° en el PDF.

### ¬øC√≥mo se hacen?
- Se utiliza un PDF base fijo para todas las pruebas.
- Un archivo CSV contiene varias preguntas, junto con las respuestas esperadas.
- Se ejecuta autom√°ticamente una comparaci√≥n entre:
   - Pregunta
   - Respuesta esperada
   - Respuesta obtenida por el chatbot
   - Se genera un nuevo archivo CSV con los resultados y una columna de precisi√≥n estimada.

### ¬øD√≥nde est√°n las pruebas?
Las pruebas est√°n en el archivo:
- üìÑ pruebas_chatbot_vector_pdf.ipynb

Pod√©s abrirlo en Google Colab, cargar tu propio PDF y CSV de preguntas, y ejecutar el an√°lisis autom√°tico para ver c√≥mo responde el modelo frente a preguntas conocidas.

